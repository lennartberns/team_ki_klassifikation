{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Festlegung des Device\n",
    "import platform\n",
    "\n",
    "# Laden der Daten\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Operationen mit Texten\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import spacy\n",
    "\n",
    "# Modell\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "# Evaluierung\n",
    "import torchmetrics\n",
    "\n",
    "# Auswertung der Evaluation\n",
    "import pandas as pd\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Versionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchtext: 0.13.1\n",
      "torch: 1.12.1\n",
      "torchmetrics: 0.9.3\n",
      "spacy: 3.4.2\n",
      "altair: 4.2.0\n",
      "pandas: 1.4.3\n"
     ]
    }
   ],
   "source": [
    "for package in [torchtext,torch, torchmetrics, spacy, alt, pd]:\n",
    "    print(f'{package.__name__}: {package.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device Auswahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    \"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erstellung Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_df = pd.read_excel('data/clean/Google_Rezensionen.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeamGoogleBewertungenDataSet(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = comment_df[index]['Kommentar']\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bestimmung Test- und Traningsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Länge der Test- und Traningsdaten bestimmen\n",
    "dataset = TeamGoogleBewertungenDataSet(comment_df)\n",
    "len_train = round(len(dataset)* 0.7)\n",
    "len_test = round(len(dataset) * 0.3)\n",
    "assert len(comment_df) == len_train + len_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zufällige Aufsplittung der Anzahl von Test- und Trainingsdaten\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [len_train, len_test]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = get_tokenizer('spacy', language='de_core_news_lg',)\n",
    "tokenizer = get_tokenizer(\n",
    "    'spacy', \n",
    "    language='de_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', \"isn't\", 'a', 'very', 'long', 'example', '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Beispiel für Anwendung des tokenizer\n",
    "sentence = \"This isn't a very long example.\"\n",
    "tokenizer(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vokabular erstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vokabular wird nicht erstellt !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter):\n",
    "    for text, _ in data_iter:\n",
    "        yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3533"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = yield_tokens(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(tokens, min_freq=2, specials=[\"<unk>\"])\n",
    "\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['Hallo', 'sehr', 'Personal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.lookup_token(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot = torch.zeros(1,len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = vocab(['nette', 'Bedienung', 'sauber'])\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text, vocab):\n",
    "    tokens = tokenizer(text)\n",
    "    onehot = torch.zeros(1,len(vocab))\n",
    "    onehot[:,vocab(tokens)] = 1\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erstellung Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pipeline = lambda x: int(x) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    " \n",
    "    for (_text,_label) in batch:\n",
    "    \n",
    "        # Vorverarbeitung der Label\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        \n",
    "        # Vorverarbeitung der Texte\n",
    "        processed_text = encode(_text, vocab)\n",
    "        \n",
    "        # Zusammenführen sämtlicher Textrepräsentationen in einer Liste\n",
    "        text_list.append(processed_text)\n",
    " \n",
    "    # Zusammenführen aller Label in einem Tensor\n",
    "    labels = torch.tensor(label_list, dtype=torch.int64)\n",
    "    \n",
    "    # Verbinden der Tensoren in text_list zu einem Tensor\n",
    "    texts = torch.cat(text_list, dim = 0)\n",
    "    \n",
    "    # Ausgabe der Texte und der Label\n",
    "    return texts.to(device), labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    " train_set, batch_size=64,\n",
    " shuffle=True,\n",
    " collate_fn=collate_batch,\n",
    " num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architektur und Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architektur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearTextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, num_class):\n",
    "        super(LinearTextClassificationModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(vocab_size, 200)\n",
    "        self.fc2 = nn.Linear(200, num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "num_class = 5\n",
    "model = LinearTextClassificationModel(vocab_size, num_class).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "\n",
    "## Festlegung Lernrate\n",
    "learning_rate = 0.05\n",
    "\n",
    "## Initialisierung Fehlerfunktion\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "## Initialisierung Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate, momentum=0.9)\n",
    "\n",
    "## Definition der Epochen\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = torchmetrics.Accuracy().to(device)\n",
    "\n",
    "loss_hist = {}\n",
    "accuracy_hist = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training funktioniert nicht !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "392",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\flori\\anaconda3\\envs\\ki_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\flori\\anaconda3\\envs\\ki_env\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\flori\\anaconda3\\envs\\ki_env\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 392",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\flori\\Documents\\KI\\ki_projekt\\team_ki_klassifikation\\NeuronalesNetz.ipynb Zelle 43\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/flori/Documents/KI/ki_projekt/team_ki_klassifikation/NeuronalesNetz.ipynb#Y112sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m running_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/flori/Documents/KI/ki_projekt/team_ki_klassifikation/NeuronalesNetz.ipynb#Y112sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m num_batches \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/flori/Documents/KI/ki_projekt/team_ki_klassifikation/NeuronalesNetz.ipynb#Y112sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m (text, label) \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/flori/Documents/KI/ki_projekt/team_ki_klassifikation/NeuronalesNetz.ipynb#Y112sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     num_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/flori/Documents/KI/ki_projekt/team_ki_klassifikation/NeuronalesNetz.ipynb#Y112sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     pred \u001b[39m=\u001b[39m model(text)\n",
      "File \u001b[1;32mc:\\Users\\flori\\anaconda3\\envs\\ki_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\flori\\anaconda3\\envs\\ki_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\flori\\anaconda3\\envs\\ki_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\flori\\anaconda3\\envs\\ki_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\flori\\anaconda3\\envs\\ki_env\\lib\\site-packages\\torch\\utils\\data\\dataset.py:290\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[1;32m--> 290\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "\u001b[1;32mc:\\Users\\flori\\Documents\\KI\\ki_projekt\\team_ki_klassifikation\\NeuronalesNetz.ipynb Zelle 43\u001b[0m in \u001b[0;36mTeamGoogleBewertungenDataSet.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/flori/Documents/KI/ki_projekt/team_ki_klassifikation/NeuronalesNetz.ipynb#Y112sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/flori/Documents/KI/ki_projekt/team_ki_klassifikation/NeuronalesNetz.ipynb#Y112sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     text \u001b[39m=\u001b[39m comment_df[index][\u001b[39m'\u001b[39m\u001b[39mKommentar\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/flori/Documents/KI/ki_projekt/team_ki_klassifikation/NeuronalesNetz.ipynb#Y112sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m text\n",
      "File \u001b[1;32mc:\\Users\\flori\\anaconda3\\envs\\ki_env\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\flori\\anaconda3\\envs\\ki_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 392"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # Dokumentation Loss -> Erkennung ob Netz konvergiert\n",
    "    running_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    for (text, label) in train_loader:\n",
    "        num_batches += 1\n",
    "        pred = model(text)\n",
    "        # Der Fehler wird berechnet\n",
    "        loss = loss_fn(pred, label)\n",
    "        # Der Fehler wird über das Netz zurückpropagiert\n",
    "        loss.backward()\n",
    "        # Die Gewichte werden angepasst\n",
    "        optimizer.step()\n",
    "        # Gradienten zurücksetzen\n",
    "        optimizer.zero_grad()\n",
    "        ## Bestimmung der Accuracy für den Batch\n",
    "        train_accuracy(pred, label)\n",
    "        \n",
    "        # running loss\n",
    "        running_loss +=loss.item()\n",
    " \n",
    "    loss_hist[epoch] = running_loss/num_batches\n",
    " \n",
    "    batch_train_accuracy = train_accuracy.compute()\n",
    "    print(f\"Training Accuracy for epoch {epoch}:{batch_train_accuracy}\")\n",
    "    accuracy_hist[epoch] = batch_train_accuracy.cpu().item()\n",
    "    train_accuracy.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auswertung Fehlerentwicklung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 1 elements, new values have 2 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\flori\\Documents\\KI\\ki_projekt\\team_ki_klassifikation\\NeuronalesNetz.ipynb Zelle 45\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/flori/Documents/KI/ki_projekt/team_ki_klassifikation/NeuronalesNetz.ipynb#Y113sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m loss_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_dict(loss_hist, orient\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/flori/Documents/KI/ki_projekt/team_ki_klassifikation/NeuronalesNetz.ipynb#Y113sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m loss_df\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mEpoch\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLoss\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/flori/Documents/KI/ki_projekt/team_ki_klassifikation/NeuronalesNetz.ipynb#Y113sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m loss_df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\flori\\anaconda3\\envs\\ki_env\\lib\\site-packages\\pandas\\core\\generic.py:5588\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5586\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   5587\u001b[0m     \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(\u001b[39mself\u001b[39m, name)\n\u001b[1;32m-> 5588\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__setattr__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name, value)\n\u001b[0;32m   5589\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[0;32m   5590\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\flori\\anaconda3\\envs\\ki_env\\lib\\site-packages\\pandas\\_libs\\properties.pyx:70\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\flori\\anaconda3\\envs\\ki_env\\lib\\site-packages\\pandas\\core\\generic.py:769\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_axis\u001b[39m(\u001b[39mself\u001b[39m, axis: \u001b[39mint\u001b[39m, labels: Index) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    768\u001b[0m     labels \u001b[39m=\u001b[39m ensure_index(labels)\n\u001b[1;32m--> 769\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mset_axis(axis, labels)\n\u001b[0;32m    770\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mc:\\Users\\flori\\anaconda3\\envs\\ki_env\\lib\\site-packages\\pandas\\core\\internals\\managers.py:214\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_axis\u001b[39m(\u001b[39mself\u001b[39m, axis: \u001b[39mint\u001b[39m, new_labels: Index) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_set_axis(axis, new_labels)\n\u001b[0;32m    215\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis] \u001b[39m=\u001b[39m new_labels\n",
      "File \u001b[1;32mc:\\Users\\flori\\anaconda3\\envs\\ki_env\\lib\\site-packages\\pandas\\core\\internals\\base.py:69\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39melif\u001b[39;00m new_len \u001b[39m!=\u001b[39m old_len:\n\u001b[1;32m---> 69\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     70\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLength mismatch: Expected axis has \u001b[39m\u001b[39m{\u001b[39;00mold_len\u001b[39m}\u001b[39;00m\u001b[39m elements, new \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalues have \u001b[39m\u001b[39m{\u001b[39;00mnew_len\u001b[39m}\u001b[39;00m\u001b[39m elements\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 1 elements, new values have 2 elements"
     ]
    }
   ],
   "source": [
    "loss_df = pd.DataFrame.from_dict(loss_hist, orient= 'index').reset_index()\n",
    "\n",
    "loss_df.columns = ['Epoch', 'Loss']\n",
    "loss_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chart = alt.Chart(loss_df).mark_line().encode(\n",
    "    x=alt.X('Epoch', title = 'Anzahl Epochen'),\n",
    "    y=alt.Y('Loss', title = 'Mittlerer Fehler')\n",
    ")\n",
    "# glue('train-loss-team', train_chart,display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auswertung Genauigkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 1 elements, new values have 2 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\flori\\Documents\\KI\\ki_projekt\\team_ki_klassifikation\\NeuronalesNetz.ipynb Zelle 49\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/flori/Documents/KI/ki_projekt/team_ki_klassifikation/NeuronalesNetz.ipynb#Y116sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m accuracy_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_dict(accuracy_hist, orient \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/flori/Documents/KI/ki_projekt/team_ki_klassifikation/NeuronalesNetz.ipynb#Y116sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m accuracy_df\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mEpoch\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/flori/Documents/KI/ki_projekt/team_ki_klassifikation/NeuronalesNetz.ipynb#Y116sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m accuracy_df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\flori\\anaconda3\\envs\\ki_env\\lib\\site-packages\\pandas\\core\\generic.py:5588\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5586\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   5587\u001b[0m     \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(\u001b[39mself\u001b[39m, name)\n\u001b[1;32m-> 5588\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__setattr__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name, value)\n\u001b[0;32m   5589\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[0;32m   5590\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\flori\\anaconda3\\envs\\ki_env\\lib\\site-packages\\pandas\\_libs\\properties.pyx:70\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\flori\\anaconda3\\envs\\ki_env\\lib\\site-packages\\pandas\\core\\generic.py:769\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_axis\u001b[39m(\u001b[39mself\u001b[39m, axis: \u001b[39mint\u001b[39m, labels: Index) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    768\u001b[0m     labels \u001b[39m=\u001b[39m ensure_index(labels)\n\u001b[1;32m--> 769\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mset_axis(axis, labels)\n\u001b[0;32m    770\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mc:\\Users\\flori\\anaconda3\\envs\\ki_env\\lib\\site-packages\\pandas\\core\\internals\\managers.py:214\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_axis\u001b[39m(\u001b[39mself\u001b[39m, axis: \u001b[39mint\u001b[39m, new_labels: Index) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_set_axis(axis, new_labels)\n\u001b[0;32m    215\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis] \u001b[39m=\u001b[39m new_labels\n",
      "File \u001b[1;32mc:\\Users\\flori\\anaconda3\\envs\\ki_env\\lib\\site-packages\\pandas\\core\\internals\\base.py:69\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39melif\u001b[39;00m new_len \u001b[39m!=\u001b[39m old_len:\n\u001b[1;32m---> 69\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     70\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLength mismatch: Expected axis has \u001b[39m\u001b[39m{\u001b[39;00mold_len\u001b[39m}\u001b[39;00m\u001b[39m elements, new \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalues have \u001b[39m\u001b[39m{\u001b[39;00mnew_len\u001b[39m}\u001b[39;00m\u001b[39m elements\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 1 elements, new values have 2 elements"
     ]
    }
   ],
   "source": [
    "accuracy_df = pd.DataFrame.from_dict(accuracy_hist, orient = 'index').reset_index()\n",
    "accuracy_df.columns = ['Epoch', 'Accuracy']\n",
    "accuracy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_chart = alt.Chart(accuracy_df).mark_line().encode(\n",
    "    x=alt.X('Epoch',title = 'Anzahl Epochen'),\n",
    "    y=alt.Y('Accuracy', title = 'Genauigkeit')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ki_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "098892d48f3e025e747a38eef60a03c94d60c10d6bd544bd547a6cb3074817d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
